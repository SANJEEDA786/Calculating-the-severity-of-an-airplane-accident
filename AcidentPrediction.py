# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JshX_JOm2d_PZNjQbcFxg7dQvOGS6RUA
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import seaborn as sns

df=pd.read_csv("train.csv")
df.head()

df['Severity'].value_counts()

df.describe()

sns.barplot(y="Safety_Score", x="Days_Since_Inspection", hue="Severity", data=df)

sns.barplot(y="Control_Metric", x="Violations", hue="Severity", data=df)

sns.catplot(y="Cabin_Temperature", x="Violations", hue="Severity",kind="bar", data=df)

sns.barplot(x="Accident_Type_Code", y="Max_Elevation", hue="Severity", data=df)

sns.barplot(x="Accident_Type_Code", y="Adverse_Weather_Metric", hue="Severity", data=df)

# d={"Highly_Fatal_And_Damaging":1,"Significant_Damage_And_Serious_Injuries":2,"Significant_Damage_And_Fatalities": 3,"Minor_Damage_And_Injuries": 4}
# df['Severity']=df['Severity'].map(d)

df['Severity'].value_counts()

X=df.drop(['Accident_ID','Severity','Accident_Type_Code'], axis=1)
y=df['Severity']
X.head(n=5)

from sklearn.preprocessing import MinMaxScaler

# Instantiate MinMaxScaler and use it to rescale X_train and X_test
scaler = MinMaxScaler(feature_range=(0,1))
rescaledX=scaler.fit_transform(X)

from sklearn.model_selection import train_test_split
xtrain,xtest,ytrain,ytest=train_test_split(rescaledX,y,test_size=0.25, random_state=2)

from sklearn.svm import SVC
clf2=SVC(gamma='auto')
clf2.fit(xtrain,ytrain)
ypred2=clf2.predict(xtest)

from sklearn.metrics import f1_score
z=100*f1_score(ytest,ypred2, average='weighted')
print(z)

# from sklearn.ensemble import RandomForestClassifier
# clf1=RandomForestClassifier(n_estimators=1000,n_jobs=-1,max_features='log2', random_state=1)
# clf1.fit(xtrain,ytrain)
# ypred=clf1.predict(xtest)
# #285

# from sklearn.model_selection import cross_val_score
# scores = cross_val_score(clf1, xtrain, ytrain, cv=5)
# scores.mean()

# from sklearn.metrics import f1_score
# z=100*f1_score(ytest,ypred, average='weighted')
# print(z)

# from sklearn.model_selection import GridSearchCV
# param_grid = { 
#     'n_estimators': [1230, 1170, 1200],
#     'max_features': ['log2'],
#     'max_depth': [2, 3, 5, 10],
#     'n_jobs':[-1]
# }

# grid_model = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv= 5)
# grid_model_result = grid_model.fit(rescaledX,y)

# # Summarize results
# best_score, best_params = grid_model_result.best_score_,grid_model_result.best_params_
# print("Best: %f using %s" % (best_score, best_params))

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import make_scorer, accuracy_score,f1_score
from sklearn.model_selection import GridSearchCV
# Choose the type of classifier. 
clf = RandomForestClassifier()

# Choose some parameter combinations to try
parameters = { 
    'n_estimators': [1240],
    'max_features': ['log2'],
     'max_depth': [15, 10],
     'criterion': ['entropy', 'gini'],
    'n_jobs':[-1]
}

# Type of scoring used to compare parameter combinations
acc_scorer = make_scorer(f1_score,average='weighted')

# Run the grid search
grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)
grid_obj = grid_obj.fit(rescaledX,y)


# Set the clf to the best combination of parameters
clf = grid_obj.best_estimator_

best_score, best_params = grid_obj.best_score_,grid_obj.best_params_
print("Best: %f using %s" % (best_score, best_params))

# Fit the best algorithm to the data. 
clf.fit(xtrain, ytrain)
#Prediction
predictions = clf.predict(xtest)
print(f1_score(ytest, predictions, average='weighted'))

from sklearn.model_selection import KFold

def run_kfold(clf):
    kf = KFold(n_splits=10, shuffle=True)
    outcomes = []
    fold = 0
    for train_index, test_index in kf.split(rescaledX):
         fold+=1
         X_train, X_test = rescaledX[train_index], rescaledX[test_index]
         y_train, y_test = y[train_index], y[test_index]
         clf.fit(X_train, y_train)
         predictions = clf.predict(X_test)
         accuracy = f1_score(y_test, predictions,average='weighted')
         outcomes.append(accuracy)
         print("Fold {0} accuracy: {1}".format(fold, accuracy))     
    mean_outcome = np.mean(outcomes)
    print("Mean Accuracy: {0}".format(mean_outcome)) 

run_kfold(clf)

df1=pd.read_csv("test.csv")
ids = df1['Accident_ID']
clf=clf.fit(rescaledX,y)
rescaledd=scaler.fit_transform(df1.drop(['Accident_ID','Accident_Type_Code'], axis=1))
predictions = clf.predict(rescaledd)
output = pd.DataFrame({ 'Accident_ID' : ids, 'Severity': predictions })
# output.to_csv('titanic-predictions.csv', index = False)
output['Severity'].value_counts()

output.to_csv('AccidentPrediction.csv', index = False)

